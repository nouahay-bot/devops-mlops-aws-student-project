{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "√âTAPE B : ENTRA√éNEMENT DU MOD√àLE ML"
   ],
   "metadata": {
    "id": "Wnwuw3PbDOlV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.1 ‚Äî Chargement et exploration du dataset"
   ],
   "metadata": {
    "id": "7dTBuudFDRxa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuration du style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "\n",
    "# Chargement du dataset Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Cr√©ation d'un DataFrame\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['target'] = y\n",
    "df['species'] = df['target'].map({0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'})\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET IRIS - INFORMATIONS G√âN√âRALES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä Forme du dataset : {df.shape}\")\n",
    "print(f\"üìä Nombre de features : {X.shape[1]}\")\n",
    "print(f\"üìä Nombre de classes : {len(np.unique(y))}\")\n",
    "print(f\"üìä Classes : {iris.target_names.tolist()}\")\n",
    "print(f\"\\nüìä Statistiques du dataset :\")\n",
    "print(df.describe())\n",
    "print(f\"\\nüìä Distribution des classes :\")\n",
    "print(df['species'].value_counts())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1qdhA8HuD1E3",
    "outputId": "70356142-cf4d-4641-acd3-e6a4f023ad65"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.2 ‚Äî Visualisations exploratoires (EDA)"
   ],
   "metadata": {
    "id": "5ZyhocOADcPN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.2.1 ‚Äî Distribution des classes"
   ],
   "metadata": {
    "id": "pgqf-pxHD98H"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Figure 1 : Distribution des classes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Graphique 1 : Histogramme\n",
    "df['species'].value_counts().plot(kind='bar', ax=axes[0], color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[0].set_title('Distribution des esp√®ces (Nombre d\\'observations)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Nombre d\\'observations', fontsize=12)\n",
    "axes[0].set_xlabel('Esp√®ce', fontsize=12)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
    "\n",
    "# Graphique 2 : Pie chart\n",
    "df['species'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%',\n",
    "                                   colors=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                                   labels=['Setosa', 'Versicolor', 'Virginica'])\n",
    "axes[1].set_title('Proportion des esp√®ces', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('1_distribution_classes.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Graphique sauvegard√© : 1_distribution_classes.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "Hbrvd88CEA3O",
    "outputId": "0859ac80-f958-41c1-d3d9-cb281754ddd9"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.2.2 ‚Äî Visualisation multidimensionnelle (Pairplot)"
   ],
   "metadata": {
    "id": "u31K0TR7EFfJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Figure 2 : Pairplot - Relations entre features\n",
    "fig = plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Pairplot avec seaborn\n",
    "g = sns.pairplot(df, hue='species', diag_kind='hist',\n",
    "                 palette={'Setosa': '#FF6B6B', 'Versicolor': '#4ECDC4', 'Virginica': '#45B7D1'},\n",
    "                 plot_kws={'alpha': 0.6, 's': 80},\n",
    "                 diag_kws={'bins': 20})\n",
    "\n",
    "g.fig.suptitle('Pairplot - Relations entre les features par esp√®ce',\n",
    "               fontsize=16, fontweight='bold', y=1.001)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('2_pairplot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Graphique sauvegard√© : 2_pairplot.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "id": "xWHVUjNqEGPR",
    "outputId": "d6a0802e-8f32-4f66-c8a4-a152d7aa54b1"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.2.3 ‚Äî Heatmap de corr√©lation"
   ],
   "metadata": {
    "id": "MRGfvPgmELBA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Figure 3 : Matrice de corr√©lation\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "correlation_matrix = df.iloc[:, :-2].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            square=True, cbar_kws={\"shrink\": 0.8}, ax=ax,\n",
    "            vmin=-1, vmax=1, center=0)\n",
    "\n",
    "ax.set_title('Matrice de corr√©lation des features', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('3_correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Graphique sauvegard√© : 3_correlation_heatmap.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "id": "T0Z1nn_iEN0Y",
    "outputId": "587dfdd7-b879-4b71-9956-89839a633490"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.2.4 ‚Äî Bo√Ætes √† moustaches (Box plots)"
   ],
   "metadata": {
    "id": "4VNEGRswEQbp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Figure 4 : Box plots par feature\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "features = df.columns[:-2]\n",
    "for idx, feature in enumerate(features):\n",
    "    sns.boxplot(data=df, x='species', y=feature, ax=axes[idx],\n",
    "                palette={'Setosa': '#FF6B6B', 'Versicolor': '#4ECDC4', 'Virginica': '#45B7D1'})\n",
    "    axes[idx].set_title(f'Distribution de {feature}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel(feature, fontsize=11)\n",
    "    axes[idx].set_xlabel('Esp√®ce', fontsize=11)\n",
    "\n",
    "plt.suptitle('Box plots - Distribution des features par esp√®ce', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('4_boxplots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Graphique sauvegard√© : 4_boxplots.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 946
    },
    "id": "k7NikBJ2ESme",
    "outputId": "a8caa7c9-d523-4ab5-9fab-37dfe1cec215"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.3 ‚Äî Pr√©paration des donn√©es"
   ],
   "metadata": {
    "id": "t7p0lA3IEVrj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PR√âPARATION DES DONN√âES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Split train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Split effectu√© :\")\n",
    "print(f\"   - Taille train : {X_train.shape[0]} observations (80%)\")\n",
    "print(f\"   - Taille test : {X_test.shape[0]} observations (20%)\")\n",
    "\n",
    "# V√©rification du stratified split\n",
    "print(f\"\\n‚úì Distribution des classes en train :\")\n",
    "for i, class_name in enumerate(iris.target_names):\n",
    "    count = (y_train == i).sum()\n",
    "    print(f\"   - {class_name} : {count} observations\")\n",
    "\n",
    "print(f\"\\n‚úì Distribution des classes en test :\")\n",
    "for i, class_name in enumerate(iris.target_names):\n",
    "    count = (y_test == i).sum()\n",
    "    print(f\"   - {class_name} : {count} observations\")\n",
    "\n",
    "# Normalisation des features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n‚úì Normalisation effectu√©e (StandardScaler) :\")\n",
    "print(f\"   - Moyenne train (avant) : {X_train.mean():.4f}\")\n",
    "print(f\"   - Moyenne train (apr√®s) : {X_train_scaled.mean():.4f}\")\n",
    "print(f\"   - Std train (avant) : {X_train.std():.4f}\")\n",
    "print(f\"   - Std train (apr√®s) : {X_train_scaled.std():.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIbSFgjSEZIX",
    "outputId": "1a767172-24c6-4a50-c06a-3f193e804787"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualisation : Avant/Apr√®s normalisation"
   ],
   "metadata": {
    "id": "n9fYosDdEaZo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Figure 5 : Avant/Apr√®s normalisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Avant normalisation\n",
    "axes[0].hist(X_train.flatten(), bins=30, color='#FF6B6B', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Distribution des features AVANT normalisation', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Valeurs', fontsize=11)\n",
    "axes[0].set_ylabel('Fr√©quence', fontsize=11)\n",
    "axes[0].axvline(X_train.mean(), color='red', linestyle='--', linewidth=2, label=f'Moyenne: {X_train.mean():.2f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Apr√®s normalisation\n",
    "axes[1].hist(X_train_scaled.flatten(), bins=30, color='#4ECDC4', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title('Distribution des features APR√àS normalisation', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Valeurs', fontsize=11)\n",
    "axes[1].set_ylabel('Fr√©quence', fontsize=11)\n",
    "axes[1].axvline(X_train_scaled.mean(), color='red', linestyle='--', linewidth=2, label=f'Moyenne: {X_train_scaled.mean():.2f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('5_normalization_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Graphique sauvegard√© : 5_normalization_comparison.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "zv64-BFcEcx3",
    "outputId": "f2c65a18-968f-48ac-838a-76ebd9daa9ba"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.4 ‚Äî Entra√Ænement de plusieurs mod√®les"
   ],
   "metadata": {
    "id": "vKZx1quAEgb1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENTRA√éNEMENT DES MOD√àLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Dictionnaire pour stocker les mod√®les et leurs performances\n",
    "models_info = {}\n",
    "\n",
    "# ============================================================================\n",
    "# MOD√àLE 1 : DECISION TREE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"MOD√àLE 1 : DECISION TREE CLASSIFIER\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42, min_samples_split=5)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "dt_train_pred = dt_model.predict(X_train_scaled)\n",
    "dt_test_pred = dt_model.predict(X_test_scaled)\n",
    "\n",
    "# M√©triques\n",
    "dt_train_accuracy = accuracy_score(y_train, dt_train_pred)\n",
    "dt_test_accuracy = accuracy_score(y_test, dt_test_pred)\n",
    "dt_precision = precision_score(y_test, dt_test_pred, average='weighted')\n",
    "dt_recall = recall_score(y_test, dt_test_pred, average='weighted')\n",
    "dt_f1 = f1_score(y_test, dt_test_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nüìä Hyperparam√®tres :\")\n",
    "print(f\"   - max_depth : 5\")\n",
    "print(f\"   - min_samples_split : 5\")\n",
    "print(f\"   - random_state : 42\")\n",
    "\n",
    "print(f\"\\nüìä Performances :\")\n",
    "print(f\"   - Accuracy (train) : {dt_train_accuracy:.4f} ({dt_train_accuracy*100:.2f}%)\")\n",
    "print(f\"   - Accuracy (test)  : {dt_test_accuracy:.4f} ({dt_test_accuracy*100:.2f}%)\")\n",
    "print(f\"   - Precision        : {dt_precision:.4f}\")\n",
    "print(f\"   - Recall           : {dt_recall:.4f}\")\n",
    "print(f\"   - F1-Score         : {dt_f1:.4f}\")\n",
    "\n",
    "models_info['Decision Tree'] = {\n",
    "    'model': dt_model,\n",
    "    'train_acc': dt_train_accuracy,\n",
    "    'test_acc': dt_test_accuracy,\n",
    "    'precision': dt_precision,\n",
    "    'recall': dt_recall,\n",
    "    'f1': dt_f1,\n",
    "    'predictions': dt_test_pred,\n",
    "    'confusion_matrix': confusion_matrix(y_test, dt_test_pred)\n",
    "}\n",
    "\n",
    "print(f\"\\nüìã Rapport de classification :\")\n",
    "print(classification_report(y_test, dt_test_pred, target_names=iris.target_names))\n",
    "\n",
    "# ============================================================================\n",
    "# MOD√àLE 2 : RANDOM FOREST\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"MOD√àLE 2 : RANDOM FOREST CLASSIFIER\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10,\n",
    "                                   random_state=42, min_samples_split=5)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "rf_train_pred = rf_model.predict(X_train_scaled)\n",
    "rf_test_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# M√©triques\n",
    "rf_train_accuracy = accuracy_score(y_train, rf_train_pred)\n",
    "rf_test_accuracy = accuracy_score(y_test, rf_test_pred)\n",
    "rf_precision = precision_score(y_test, rf_test_pred, average='weighted')\n",
    "rf_recall = recall_score(y_test, rf_test_pred, average='weighted')\n",
    "rf_f1 = f1_score(y_test, rf_test_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nüìä Hyperparam√®tres :\")\n",
    "print(f\"   - n_estimators : 100\")\n",
    "print(f\"   - max_depth : 10\")\n",
    "print(f\"   - min_samples_split : 5\")\n",
    "print(f\"   - random_state : 42\")\n",
    "\n",
    "print(f\"\\nüìä Performances :\")\n",
    "print(f\"   - Accuracy (train) : {rf_train_accuracy:.4f} ({rf_train_accuracy*100:.2f}%)\")\n",
    "print(f\"   - Accuracy (test)  : {rf_test_accuracy:.4f} ({rf_test_accuracy*100:.2f}%)\")\n",
    "print(f\"   - Precision        : {rf_precision:.4f}\")\n",
    "print(f\"   - Recall           : {rf_recall:.4f}\")\n",
    "print(f\"   - F1-Score         : {rf_f1:.4f}\")\n",
    "\n",
    "models_info['Random Forest'] = {\n",
    "    'model': rf_model,\n",
    "    'train_acc': rf_train_accuracy,\n",
    "    'test_acc': rf_test_accuracy,\n",
    "    'precision': rf_precision,\n",
    "    'recall': rf_recall,\n",
    "    'f1': rf_f1,\n",
    "    'predictions': rf_test_pred,\n",
    "    'confusion_matrix': confusion_matrix(y_test, rf_test_pred),\n",
    "    'feature_importance': rf_model.feature_importances_\n",
    "}\n",
    "\n",
    "print(f\"\\nüìã Rapport de classification :\")\n",
    "print(classification_report(y_test, rf_test_pred, target_names=iris.target_names))\n",
    "\n",
    "# ============================================================================\n",
    "# MOD√àLE 3 : LOGISTIC REGRESSION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"MOD√àLE 3 : LOGISTIC REGRESSION\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=200, random_state=42,\n",
    "                               solver='lbfgs', multi_class='multinomial')\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "lr_train_pred = lr_model.predict(X_train_scaled)\n",
    "lr_test_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# M√©triques\n",
    "lr_train_accuracy = accuracy_score(y_train, lr_train_pred)\n",
    "lr_test_accuracy = accuracy_score(y_test, lr_test_pred)\n",
    "lr_precision = precision_score(y_test, lr_test_pred, average='weighted')\n",
    "lr_recall = recall_score(y_test, lr_test_pred, average='weighted')\n",
    "lr_f1 = f1_score(y_test, lr_test_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nüìä Hyperparam√®tres :\")\n",
    "print(f\"   - max_iter : 200\")\n",
    "print(f\"   - solver : lbfgs\")\n",
    "print(f\"   - multi_class : multinomial\")\n",
    "print(f\"   - random_state : 42\")\n",
    "\n",
    "print(f\"\\nüìä Performances :\")\n",
    "print(f\"   - Accuracy (train) : {lr_train_accuracy:.4f} ({lr_train_accuracy*100:.2f}%)\")\n",
    "print(f\"   - Accuracy (test)  : {lr_test_accuracy:.4f} ({lr_test_accuracy*100:.2f}%)\")\n",
    "print(f\"   - Precision        : {lr_precision:.4f}\")\n",
    "print(f\"   - Recall           : {lr_recall:.4f}\")\n",
    "print(f\"   - F1-Score         : {lr_f1:.4f}\")\n",
    "\n",
    "models_info['Logistic Regression'] = {\n",
    "    'model': lr_model,\n",
    "    'train_acc': lr_train_accuracy,\n",
    "    'test_acc': lr_test_accuracy,\n",
    "    'precision': lr_precision,\n",
    "    'recall': lr_recall,\n",
    "    'f1': lr_f1,\n",
    "    'predictions': lr_test_pred,\n",
    "    'confusion_matrix': confusion_matrix(y_test, lr_test_pred)\n",
    "}\n",
    "\n",
    "print(f\"\\nüìã Rapport de classification :\")\n",
    "print(classification_report(y_test, lr_test_pred, target_names=iris.target_names))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpw7ZOmeEjGz",
    "outputId": "c4c6a0f2-8525-4b70-9a4f-8c8fc3c7ebce"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.5 ‚Äî Comparaison des mod√®les"
   ],
   "metadata": {
    "id": "I-5eofPIEnN6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARAISON DES MOD√àLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Tableau comparatif\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Mod√®le': models_info.keys(),\n",
    "    'Accuracy (Train)': [models_info[m]['train_acc'] for m in models_info],\n",
    "    'Accuracy (Test)': [models_info[m]['test_acc'] for m in models_info],\n",
    "    'Precision': [models_info[m]['precision'] for m in models_info],\n",
    "    'Recall': [models_info[m]['recall'] for m in models_info],\n",
    "    'F1-Score': [models_info[m]['f1'] for m in models_info]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# D√©tection du meilleur mod√®le\n",
    "best_model_name = comparison_df.loc[comparison_df['Accuracy (Test)'].idxmax(), 'Mod√®le']\n",
    "best_accuracy = comparison_df['Accuracy (Test)'].max()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úì MEILLEUR MOD√àLE : {best_model_name}\")\n",
    "print(f\"‚úì ACCURACY : {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "print(f\"{'='*80}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YcZZjdUtEpyv",
    "outputId": "6ff26722-cea3-4fe4-b905-7dd05c29f00e"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.6 ‚Äî Visualisations des performances"
   ],
   "metadata": {
    "id": "8CLGl3g7Ewya"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.6.1 ‚Äî Comparaison des pr√©cisions"
   ],
   "metadata": {
    "id": "h20H9q-zEx9P"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Figure 6 : Comparaison des m√©triques\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['Accuracy (Train)', 'Accuracy (Test)', 'Precision', 'F1-Score']\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "\n",
    "    if metric == 'Accuracy (Train)':\n",
    "        values = [models_info[m]['train_acc'] for m in models_info]\n",
    "    elif metric == 'Accuracy (Test)':\n",
    "        values = [models_info[m]['test_acc'] for m in models_info]\n",
    "    elif metric == 'Precision':\n",
    "        values = [models_info[m]['precision'] for m in models_info]\n",
    "    else:  # F1-Score\n",
    "        values = [models_info[m]['f1'] for m in models_info]\n",
    "\n",
    "    bars = ax.bar(models_info.keys(), values, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "\n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}\\n({height*100:.2f}%)',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "    ax.set_title(metric, fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Score', fontsize=11)\n",
    "    ax.set_ylim([0.9, 1.05])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(45)\n",
    "        label.set_ha('right')\n",
    "\n",
    "plt.suptitle('Comparaison des performances des mod√®les', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('6_models_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Graphique sauvegard√© : 6_models_comparison.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "-uFJ8kQQE2BW",
    "outputId": "e02e8776-0f94-453a-fcdf-31253176378c"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.6.2 ‚Äî Matrice de confusion (Heatmaps)"
   ],
   "metadata": {
    "id": "KFKkxAR-E5nO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Figure 7 : Matrices de confusion\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "for idx, (model_name, model_data) in enumerate(models_info.items()):\n",
    "    cm = model_data['confusion_matrix']\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
    "                xticklabels=iris.target_names, yticklabels=iris.target_names,\n",
    "                cbar_kws={'label': 'Nombre de pr√©dictions'})\n",
    "\n",
    "    axes[idx].set_title(f'Matrice de confusion - {model_name}\\n(Accuracy: {model_data[\"test_acc\"]:.4f})',\n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Vraie classe', fontsize=11)\n",
    "    axes[idx].set_xlabel('Classe pr√©dite', fontsize=11)\n",
    "\n",
    "plt.suptitle('Matrices de confusion pour tous les mod√®les', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('7_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Graphique sauvegard√© : 7_confusion_matrices.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "aoP22xX1E8T6",
    "outputId": "c653e5d4-b481-4262-885d-37d0317ce54d"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.6.3 ‚Äî Feature Importance (Random Forest)"
   ],
   "metadata": {
    "id": "JEORnmbmFAxH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Figure 8 : Feature Importance du Random Forest\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "feature_importance = models_info['Random Forest']['feature_importance']\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "# Tri par importance\n",
    "sorted_indices = np.argsort(feature_importance)[::-1]\n",
    "sorted_features = [feature_names[i] for i in sorted_indices]\n",
    "sorted_importance = feature_importance[sorted_indices]\n",
    "\n",
    "bars = ax.barh(sorted_features, sorted_importance, color='#45B7D1', alpha=0.8, edgecolor='black', linewidth=2)\n",
    "\n",
    "# Ajouter les valeurs\n",
    "for i, (feature, importance) in enumerate(zip(sorted_features, sorted_importance)):\n",
    "    ax.text(importance, i, f' {importance:.4f}', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Importance', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Feature Importance - Random Forest Classifier', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('8_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Graphique sauvegard√© : 8_feature_importance.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "c_AELWDDFBrb",
    "outputId": "b2c243e7-9309-4a5e-a569-0157f78f9941"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "B.7 ‚Äî Analyse des erreurs"
   ],
   "metadata": {
    "id": "HaDauV0eFGIS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSE DES ERREURS DU MEILLEUR MOD√àLE (DECISION TREE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_model = models_info['Decision Tree']['model']\n",
    "dt_predictions = models_info['Decision Tree']['predictions']\n",
    "\n",
    "# Indices des pr√©dictions incorrectes\n",
    "incorrect_indices = np.where(dt_predictions != y_test)[0]\n",
    "\n",
    "print(f\"\\nüìä Nombre de pr√©dictions incorrectes : {len(incorrect_indices)}\")\n",
    "print(f\"üìä Taux d'erreur : {len(incorrect_indices)/len(y_test)*100:.2f}%\")\n",
    "print(f\"üìä Taux de r√©ussite : {(1 - len(incorrect_indices)/len(y_test))*100:.2f}%\")\n",
    "\n",
    "if len(incorrect_indices) > 0:\n",
    "    print(f\"\\nüìã D√©tail des erreurs ({len(incorrect_indices)} observations mal classifi√©es) :\")\n",
    "    for idx in incorrect_indices:\n",
    "        true_class = iris.target_names[y_test[idx]]\n",
    "        pred_class = iris.target_names[dt_predictions[idx]]\n",
    "        features = X_test[idx]\n",
    "        print(f\"   - Index {idx} : Pr√©diction '{pred_class}' (r√©alit√© : '{true_class}')\")\n",
    "        print(f\"     Features : {features}\")\n",
    "\n",
    "    # Analyse par classe\n",
    "    print(f\"\\nüìä Erreurs par classe :\")\n",
    "    for class_idx, class_name in enumerate(iris.target_names):\n",
    "        class_errors = sum(1 for idx in incorrect_indices if y_test[idx] == class_idx)\n",
    "        class_total = sum(1 for y in y_test if y == class_idx)\n",
    "        if class_total > 0:\n",
    "            error_rate = class_errors / class_total * 100\n",
    "            print(f\"   - {class_name} : {class_errors}/{class_total} erreurs ({error_rate:.1f}%)\")\n",
    "else:\n",
    "    print(f\"\\n‚úì Aucune erreur de pr√©diction ! (Mod√®le parfait sur l'ensemble test)\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y7lBExcJFqbF",
    "outputId": "f2ce9f31-aa52-463d-cf6d-1347fea23229"
   },
   "execution_count": 15,
   "outputs": []
  }
 ]
}
